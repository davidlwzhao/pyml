{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 & 6\n",
    "### Preprocessing, Pipelines, and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# preprocessing utilities\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import auc, accuracy_score, roc_curve, precision_score, recall_score, f1_score\n",
    "\n",
    "# estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "--- preprocessing ---\n",
    "+ Removing nulls\n",
    "+ Imputing missing values\n",
    "+ Encoding ordinal variables\n",
    "+ Encoding nominal variables\n",
    "+ Scaling variables\n",
    "+ Feature selection\n",
    "+ Feature extraction/engineering\n",
    "+ Imbalanced dataset correction(s)\n",
    "\n",
    "Steps:\n",
    "--- model selection ---\n",
    "+ Classifier choice\n",
    "+ Hyperparameter tuning (Grid Search CV, Nested K Fold)\n",
    "+ Learning curve evaluation\n",
    "+ Validation curve evaluation\n",
    "+ ROC curve / Precision Recall curve evaluation - decision function choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler().fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    return X_train_std, X_test_std, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train_std, X_test_std, y_train, y_test = prep_data(X, y)\n",
    "X_train_std_cut, X_test_std_cut, y_train_cut, y_test_cut = prep_data(X[:, [2, 3]], y)\n",
    "\n",
    "X_std_combo = np.vstack((X_train_std, X_test_std))\n",
    "X_std_combo_cut = np.vstack((X_train_std_cut, X_test_std_cut))\n",
    "y_combo = np.hstack((y_train, y_test))\n",
    "y_combo_cut = np.hstack((y_train_cut, y_test_cut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ https://scikit-learn.org/stable/modules/compose.html#featureunion-composite-feature-spaces\n",
    "+ https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n",
    "+ https://scikit-learn.org/stable/auto_examples/compose/plot_feature_union.html#sphx-glr-auto-examples-compose-plot-feature-union-py\n",
    "+ https://stackoverflow.com/questions/36113686/multiple-pipelines-that-merge-within-a-sklearn-pipeline\n",
    "+ https://towardsdatascience.com/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd\n",
    "+ https://scikit-learn.org/stable/auto_examples/preprocessing/plot_function_transformer.html\n",
    "+ https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py\n",
    "\n",
    "\n"
   ]
  }
 ]
}